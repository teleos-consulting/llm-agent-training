{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain openai langchain-community langgraph langchain-anthropic tavily-python langgraph-checkpoint-sqlite langchain-openai panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key_env = 'OPENAI_API_KEY'\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import SystemMessage, AIMessage, ToolMessage, HumanMessage\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "from random import randint\n",
    "\n",
    "if not os.environ.get(openai_key_env):\n",
    "    os.environ[openai_key_env] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "@tool\n",
    "def roll_dice(max: int = 20) -> int:\n",
    "    \"\"\"Gets a random number between 1 and 20 inclusive,\n",
    "    as in a DnD d20 roll.\n",
    "    \"\"\"\n",
    "    return randint(1, max)\n",
    "\n",
    "toolbelt = [roll_dice]\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0).bind_tools(toolbelt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "Your are a helpful utility AI bot for DnD.\n",
    "Your name is 'OAF' which stands for Onions and Flagons.\n",
    "You are pithy and brief, efficient with your information.\n",
    "Whenever a player asks if the player can do something, your response is, 'You can certainly try!'\n",
    "If they are simply asking for information or providing an instruction, you don't need to use the catch phrase.\n",
    "That's only for when they are trying to do something that may or may not work.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(system_message),\n",
    "    HumanMessage(\"Introduce yourself.\"),\n",
    "]\n",
    "\n",
    "ai_message = model.invoke(messages)\n",
    "\n",
    "messages.append(ai_message)\n",
    "\n",
    "usertext = input()\n",
    "while usertext != \"/quit\":\n",
    "    display(usertext)\n",
    "    messages.append(HumanMessage(usertext))\n",
    "    try:\n",
    "        r = model.invoke(messages)\n",
    "        display(r.content)\n",
    "        messages.append(r)\n",
    "        \n",
    "        if len(r.tool_calls) > 0:\n",
    "            for tool_call in r.tool_calls:\n",
    "                selected_tool = {\"roll_dice\": roll_dice}[tool_call[\"name\"].lower()]\n",
    "                tool_msg = selected_tool.invoke(tool_call)\n",
    "                messages.append(tool_msg)\n",
    "            r2 = model.invoke(messages)\n",
    "            \n",
    "            if r2.content != \"\":\n",
    "                display(r2.content)\n",
    "            \n",
    "            messages.append(r2)\n",
    "    except:\n",
    "        pass\n",
    "    usertext = input()\n",
    "\n",
    "display([m.content for m in messages])\n",
    "\n",
    "# print out the messages to dialogue.txt\n",
    "with open(\"dialogue.txt\", \"w\") as f:\n",
    "    for m in messages:\n",
    "        f.write(m.content + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
